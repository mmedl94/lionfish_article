\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{ajs}
\citation{leisch2018market}
\citation{Asimov1985-xr}
\citation{lee2022}
\citation{cook_manual_1997,laa2023new}
\citation{Laa2020}
\citation{leisch2018market}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of how $k$-means partitions 2D data with different association structure. If the correlation is high (C), the partitioning happens along the primary direction of the association.}}{2}{figure.1}\protected@file@percent }
\newlabel{kmeans-partition}{{1}{2}{Examples of how $k$-means partitions 2D data with different association structure. If the correlation is high (C), the partitioning happens along the primary direction of the association}{figure.1}{}}
\newlabel{interface}{{2}{2}{}{section.2}{}}
\citation{ggobi}
\citation{tourr}
\citation{laa2023new}
\citation{RJ-2023-052}
\citation{lundh1999introduction}
\citation{schimansky24}
\citation{Hunter:2007}
\citation{tourr}
\citation{reticulate}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The four $k$-means partitions plotted as histograms of the individual features. While differences between groups can be seen, the clear separation cannot. This is important for understanding why high-dimensional visualisation methods are useful for summarising partitioning results.}}{3}{figure.2}\protected@file@percent }
\newlabel{kmeans-histogram}{{2}{3}{The four $k$-means partitions plotted as histograms of the individual features. While differences between groups can be seen, the clear separation cannot. This is important for understanding why high-dimensional visualisation methods are useful for summarising partitioning results}{figure.2}{}}
\citation{ggobi}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Overview of the GUI. A: Sidebar controls; B: Display area; C: Feature selection checkboxes; D: Subset selection with color indicators; E: Frame selection interface; F: Interfaces for adjusting the number of bins of histograms, animating tours and blending out projection axes with a low norm; G: Save and load buttons; H: Interface for starting new tours; I: Metric selection interface.}}{5}{figure.3}\protected@file@percent }
\newlabel{fig:GUI_overview}{{3}{5}{Overview of the GUI. A: Sidebar controls; B: Display area; C: Feature selection checkboxes; D: Subset selection with color indicators; E: Frame selection interface; F: Interfaces for adjusting the number of bins of histograms, animating tours and blending out projection axes with a low norm; G: Save and load buttons; H: Interface for starting new tours; I: Metric selection interface}{figure.3}{}}
\citation{python}
\citation{R}
\citation{CBCH94}
\citation{lckl2005}
\newlabel{workflow}{{3}{7}{}{section.3}{}}
\citation{keim2010mastering}
\citation{dolnicar2003winter}
\citation{cliff2009formative}
\citation{leisch2018market}
\citation{flexclust}
\newlabel{applications}{{4}{9}{}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Three 2D projections from a grand tour on the Austrian Vacation Activities data. Because the 27 features are binary, you'll see some apparent clusters (left) but with this many binary features the data mostly looks continuous.}}{9}{figure.4}\protected@file@percent }
\newlabel{winter-gt}{{4}{9}{Three 2D projections from a grand tour on the Austrian Vacation Activities data. Because the 27 features are binary, you'll see some apparent clusters (left) but with this many binary features the data mostly looks continuous}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Traditional overview of clusters. Color represents (A) the intra-cluster fraction, and (B) the intra-feature fraction, with lighter indicating higher values. From A, we can see that cluster 3 tourists like alpine skiing, going out in the evening and going to discos and bars. They also like relaxing, shopping and sightseeing but these are popular among all tourists. From B, we can see the distribution of activities across clusters, e.g. most tourists who use health facilities are found in cluster 4 while tourist going to a pool or sauna are primarily found in clusters 1 and 5.}}{10}{figure.5}\protected@file@percent }
\newlabel{fig:winteractiv_heatmap}{{5}{10}{Traditional overview of clusters. Color represents (A) the intra-cluster fraction, and (B) the intra-feature fraction, with lighter indicating higher values. From A, we can see that cluster 3 tourists like alpine skiing, going out in the evening and going to discos and bars. They also like relaxing, shopping and sightseeing but these are popular among all tourists. From B, we can see the distribution of activities across clusters, e.g. most tourists who use health facilities are found in cluster 4 while tourist going to a pool or sauna are primarily found in clusters 1 and 5}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comparison of silhouette plots of two $k$-means cluster solutions of the Austrian vacation activities dataset with $k$=6. (A) shows the silhouette plot of the $k$-means solution of the full dataset and (B) the silhouette plot of the $k$-means solution of the dataset after manual feature selection. We can see that the cluster solution with the reduced dataset achieved better silhouette scores and that clusters 1 and 3 contain observations with negative silhouette scores.}}{11}{figure.6}\protected@file@percent }
\newlabel{fig:silhouette_comparison}{{6}{11}{Comparison of silhouette plots of two $k$-means cluster solutions of the Austrian vacation activities dataset with $k$=6. (A) shows the silhouette plot of the $k$-means solution of the full dataset and (B) the silhouette plot of the $k$-means solution of the dataset after manual feature selection. We can see that the cluster solution with the reduced dataset achieved better silhouette scores and that clusters 1 and 3 contain observations with negative silhouette scores}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Display of a projection of the Austrian vacation activities dataset with the six clusters of the k-means cluster solution highlighted in different colors. Projection axes with a norm < 0.1 are not shown to reduce cluttering. The colors indicate which clusters the highlighted observations belong to with cluster 1 being blue (A), cluster 2 being orange (B), cluster 3 being green (C), cluster 4 being red (D), cluster 5 being violet (E) and cluster 6 being brown (F). Some datapoints appear to be highlighted always, which occurs due to overlap of many datapoints in one spot. We can see that the projection separates some clusters well, however also that there is considerable overlap of clusters 4, 5 and 6.}}{12}{figure.7}\protected@file@percent }
\newlabel{fig:winter_activ_cluster_highlights}{{7}{12}{Display of a projection of the Austrian vacation activities dataset with the six clusters of the k-means cluster solution highlighted in different colors. Projection axes with a norm < 0.1 are not shown to reduce cluttering. The colors indicate which clusters the highlighted observations belong to with cluster 1 being blue (A), cluster 2 being orange (B), cluster 3 being green (C), cluster 4 being red (D), cluster 5 being violet (E) and cluster 6 being brown (F). Some datapoints appear to be highlighted always, which occurs due to overlap of many datapoints in one spot. We can see that the projection separates some clusters well, however also that there is considerable overlap of clusters 4, 5 and 6}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Interactive tour GUI loaded with multiple plots showing different aspects of the k-means solution of the Austrian vacation activities dataset. Projection axes with a norm < 0.1 are not shown to reduce cluttering. Top left: 2D tour with the linear discriminant analysis projection pursuit index. Top right: heatmap with the intra-cluster fraction. Bottom left: 1D tour with the linear discriminant analysis projection pursuit index. Bottom right: mosaic plot. Tourists in both clusters 1 and 3 didn't participate in skiing a lot, but tourists in cluster 3 were much more interested in going to the pool, spa and health facilities compared to cluster 1.}}{13}{figure.8}\protected@file@percent }
\newlabel{fig:winter_cl7_init}{{8}{13}{Interactive tour GUI loaded with multiple plots showing different aspects of the k-means solution of the Austrian vacation activities dataset. Projection axes with a norm < 0.1 are not shown to reduce cluttering. Top left: 2D tour with the linear discriminant analysis projection pursuit index. Top right: heatmap with the intra-cluster fraction. Bottom left: 1D tour with the linear discriminant analysis projection pursuit index. Bottom right: mosaic plot. Tourists in both clusters 1 and 3 didn't participate in skiing a lot, but tourists in cluster 3 were much more interested in going to the pool, spa and health facilities compared to cluster 1}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Interactive tour GUI loaded with multiple plots showing different aspects of the $k$-means solution of the Austrian vacation activities dataset, with manually adjusted projections. Projection axes with a norm < 0.1 have been blend out to reduce cluttering. Top left: 2D tour with a manually adjusted projection. Top right: heatmap with the intra-cluster fraction. Bottom left: 1D tour with a manually adjusted projection. Bottom right: mosaic plot. Changing the projection axes of ``going to a spa'', ``museums'', ``sightseeing'' and ``using health facilities'' reveals the preferences and overlap of clusters 1 and 3.}}{14}{figure.9}\protected@file@percent }
\newlabel{fig:winter_cl7_pre}{{9}{14}{Interactive tour GUI loaded with multiple plots showing different aspects of the $k$-means solution of the Austrian vacation activities dataset, with manually adjusted projections. Projection axes with a norm < 0.1 have been blend out to reduce cluttering. Top left: 2D tour with a manually adjusted projection. Top right: heatmap with the intra-cluster fraction. Bottom left: 1D tour with a manually adjusted projection. Bottom right: mosaic plot. Changing the projection axes of ``going to a spa'', ``museums'', ``sightseeing'' and ``using health facilities'' reveals the preferences and overlap of clusters 1 and 3}{figure.9}{}}
\citation{murtagh2014ward}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Interactive tour GUI loaded with multiple plots showing different aspects of the $k$-means solution of the Austrian vacation activities dataset, after new subsets have been selected. Projection axes with a norm < 0.1 have been blend out to reduce cluttering. Top left: 2D tour with a manually adjusted projection. Top right: heatmap with the intra-cluster fraction. Bottom left: 1D tour with a manually adjusted projection. Bottom right: mosaic plot. We can see that now almost all museum goers are in the new manually selected subset 7 and what their preferences are compared to the other clusters.}}{15}{figure.10}\protected@file@percent }
\newlabel{fig:winter_cl7_post}{{10}{15}{Interactive tour GUI loaded with multiple plots showing different aspects of the $k$-means solution of the Austrian vacation activities dataset, after new subsets have been selected. Projection axes with a norm < 0.1 have been blend out to reduce cluttering. Top left: 2D tour with a manually adjusted projection. Top right: heatmap with the intra-cluster fraction. Bottom left: 1D tour with a manually adjusted projection. Bottom right: mosaic plot. We can see that now almost all museum goers are in the new manually selected subset 7 and what their preferences are compared to the other clusters}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Dendrogram of the features of the Australian Vacation Activities dataset using Ward's method with the Jaccard index. Features which were clustered together are marked by the colored boxes. We can see, which activities had similar patterns in tourist interest.}}{16}{figure.11}\protected@file@percent }
\newlabel{fig:aus_feature_clustering}{{11}{16}{Dendrogram of the features of the Australian Vacation Activities dataset using Ward's method with the Jaccard index. Features which were clustered together are marked by the colored boxes. We can see, which activities had similar patterns in tourist interest}{figure.11}{}}
\newlabel{discussion}{{5}{17}{}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Heatmap of the intra cluster fraction (indicated by color) of the $k$-means solution with \( k = 6 \) and the reduced feature subset. We can observe that tourists in subsets 1, 2 and 6 all prefer to travel without their friends.}}{18}{figure.12}\protected@file@percent }
\newlabel{fig:aus_heatmapg}{{12}{18}{Heatmap of the intra cluster fraction (indicated by color) of the $k$-means solution with \( k = 6 \) and the reduced feature subset. We can observe that tourists in subsets 1, 2 and 6 all prefer to travel without their friends}{figure.12}{}}
\newlabel{conclusion}{{6}{18}{}{section.6}{}}
\citation{Laa2020}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Interactive tour GUI loaded with multiple plots showing different aspects of the $k$-means solution of the Australian vacation activities dataset, with the projection axes of the feature ``Friends'' pointing into one direction and all the other ones into another one. Top left: 2D tour. Top right: 1D tour. Bottom left: Mosaic plot. Bottom right: Heatmap with the intra cluster fraction. We can see how the feature ``Friends'' and the general activity level (represented by the other projection axes pointing into one direction) separates the data.}}{19}{figure.13}\protected@file@percent }
\newlabel{fig:aus_preselection}{{13}{19}{Interactive tour GUI loaded with multiple plots showing different aspects of the $k$-means solution of the Australian vacation activities dataset, with the projection axes of the feature ``Friends'' pointing into one direction and all the other ones into another one. Top left: 2D tour. Top right: 1D tour. Bottom left: Mosaic plot. Bottom right: Heatmap with the intra cluster fraction. We can see how the feature ``Friends'' and the general activity level (represented by the other projection axes pointing into one direction) separates the data}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Interactive tour GUI as seen in \ref  {fig:aus_preselection}, but after sub-selection of subsets 7 (pink), 8 (grey) and 9 (gold). Top left: 2D tour. Top right: 1D tour. Bottom left: Mosaic plot. Bottom right: Heatmap with the intra cluster fraction. We can observe the preferences of three new subsegments, which can be interpreted as very active (pink), moderately active (grey) and inactive (gold) tourists travelling without their friends.}}{20}{figure.14}\protected@file@percent }
\newlabel{fig:aus_selection}{{14}{20}{Interactive tour GUI as seen in \ref {fig:aus_preselection}, but after sub-selection of subsets 7 (pink), 8 (grey) and 9 (gold). Top left: 2D tour. Top right: 1D tour. Bottom left: Mosaic plot. Bottom right: Heatmap with the intra cluster fraction. We can observe the preferences of three new subsegments, which can be interpreted as very active (pink), moderately active (grey) and inactive (gold) tourists travelling without their friends}{figure.14}{}}
\bibdata{lionfish_references.bib}
\bibcite{Asimov1985-xr}{{1}{1985}{{Asimov}}{{}}}
\bibcite{cliff2009formative}{{2}{2009}{{Cliff}}{{}}}
\bibcite{cook_manual_1997}{{3}{1997}{{Cook and Buja}}{{}}}
\bibcite{CBCH94}{{4}{1995}{{Cook \emph  {et~al.}}}{{Cook, Buja, Cabrera, and Hurley}}}
\bibcite{ggobi}{{5}{2007}{{Cook and Swayne}}{{}}}
\bibcite{dolnicar2003winter}{{6}{2003}{{Dolnicar and Leisch}}{{}}}
\bibcite{RJ-2023-052}{{7}{2023}{{Hart and Wang}}{{}}}
\bibcite{Hunter:2007}{{8}{2007}{{Hunter}}{{}}}
\bibcite{keim2010mastering}{{9}{2010}{{Keim \emph  {et~al.}}}{{Keim, Kohlhammer, Ellis, and Mansmann}}}
\bibcite{laa2023new}{{10}{2023}{{Laa \emph  {et~al.}}}{{Laa, Aumann, Cook, and Valencia}}}
\bibcite{Laa2020}{{11}{2020}{{Laa \emph  {et~al.}}}{{Laa, Cook, and Valencia}}}
\bibcite{lckl2005}{{12}{2005}{{Lee \emph  {et~al.}}}{{Lee, Cook, Klinke, and Lumley}}}
\bibcite{lee2022}{{13}{2022}{{Lee \emph  {et~al.}}}{{Lee, Cook, da~Silva, Laa, Spyrison, Wang, and Zhang}}}
\bibcite{flexclust}{{14}{2006}{{Leisch}}{{}}}
\bibcite{leisch2018market}{{15}{2018}{{Leisch \emph  {et~al.}}}{{Leisch, Dolnicar, and Gr{\"u}n}}}
\newlabel{acknowledgements}{{7}{21}{}{section.7}{}}
\bibcite{lundh1999introduction}{{16}{1999}{{Lundh}}{{}}}
\bibcite{murtagh2014ward}{{17}{2014}{{Murtagh and Legendre}}{{}}}
\bibcite{R}{{18}{2024}{{R Core Team}}{{}}}
\bibcite{schimansky24}{{19}{2024}{{Schimansky}}{{}}}
\bibcite{reticulate}{{20}{2024}{{Ushey \emph  {et~al.}}}{{Ushey, Allaire, and Tang}}}
\bibcite{python}{{21}{2009}{{Van~Rossum and Drake}}{{}}}
\bibcite{tourr}{{22}{2011}{{Wickham \emph  {et~al.}}}{{Wickham, Cook, Hofmann, and Buja}}}
